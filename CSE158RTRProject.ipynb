{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7638e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b45d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1c335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89ef3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_runway = pd.DataFrame(list(readGz(\"./renttherunway_final_data.json.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9a9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning Cell\n",
    "rent_runway[\"bust size\"] = rent_runway[\"bust size\"].str[2:]\n",
    "rent_runway[\"weight\"] = rent_runway[\"weight\"].str[:-3].astype(float)\n",
    "rent_runway[\"height\"] = (rent_runway[\"height\"].str[0].astype(float) * 12) + rent_runway[\"height\"].str[2:-1].astype(float)\n",
    "rent_runway[\"age\"] = rent_runway[\"age\"].astype(float)\n",
    "rent_runway[\"rating\"] = rent_runway[\"rating\"].astype(float)\n",
    "rent_runway[\"review_date\"] = pd.to_datetime(rent_runway[\"review_date\"])\n",
    "rent_runway[\"year\"] = rent_runway[\"review_date\"].dt.year\n",
    "rent_runway[\"month\"] = rent_runway[\"review_date\"].dt.month\n",
    "rent_runway.loc[rent_runway[\"rented for\"] == \"party: cocktail\", \"rented for\"] = \"other\"\n",
    "rent_runway = rent_runway.drop(columns=\"review_date\")\n",
    "filtered_runway = rent_runway.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08a5e1",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421301ac",
   "metadata": {},
   "source": [
    "- Turn `category` columns into values that inform the `rented for` column\n",
    "    - If an item is not largely associated with a particular category, label it as \"general\" or \"other\"\n",
    "- Look for correlated features and point them out\n",
    "- If you have time, perform DSC80 style permutation tests with the TVD test stat to get pvalues that represent if a correlation exists with the `rented for` column\n",
    "    - These would include the following columns: \\['fit', 'body type', 'age', 'year', 'month'\\]\n",
    "- Any extra stuff would be sick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d9682",
   "metadata": {},
   "source": [
    "# Model Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d54a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_runway.drop(columns=[\"rented for\",\"user_id\",\"item_id\"])\n",
    "X[\"age\"] = pd.qcut(X[\"age\"],q=10).astype(str)\n",
    "y = filtered_runway[\"rented for\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ce8a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "categories = ['other','vacation', 'formal', 'wedding', 'date', 'everyday', 'party', 'work']\n",
    "preds = pd.DataFrame(columns=categories)\n",
    "for category in categories[1:]:\n",
    "    preds[category] = filtered_runway[\"review_text\"].str.count(category)\n",
    "preds = preds.fillna(0)\n",
    "preds = preds.T.idxmax()\n",
    "preds = preds.str.replace('formal',\"formal affair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a02ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2640868832151243"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec80b74",
   "metadata": {},
   "source": [
    "## Real Model Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cfab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = ['a', 'aa', 'b', 'c', 'd', 'd+', 'dd', 'ddd/e', 'f', 'g', 'h', 'i', 'j']\n",
    "one_hot_vars = ['fit', 'body type', 'age', 'year', 'month']\n",
    "numerical_cols = [\"weight\",\"height\",\"size\",\"rating\"]\n",
    "preper = ColumnTransformer([\n",
    "    (\"one-hot\",OneHotEncoder(), one_hot_vars),\n",
    "    (\"ordinal\", OrdinalEncoder(categories=[sizes]), ['bust size']),\n",
    "    (\"identity\", FunctionTransformer(), numerical_cols)\n",
    "])\n",
    "pipe = Pipeline([\n",
    "    (\"preproc\", preper),\n",
    "#     (\"standard\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=2000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947a83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preproc = preper.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c406c77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "selector = RFECV(LogisticRegression(), min_features_to_select=10, step=2, cv=5, n_jobs=-1)\n",
    "selector = selector.fit(X_preproc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "213a4b1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "485e57e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36396800131164564"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.score(X_preproc,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00f534",
   "metadata": {},
   "source": [
    "## Costin's NLP Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb29d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokens = nlp(\"Costin's rock.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "216ab8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def tokenize_sentence(sent):\n",
    "    return [token.text for token in nlp(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45db68ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(text_col):\n",
    "    corpus = load_corpus()\n",
    "    sents = segment_and_tokenize(corpus)\n",
    "    word_to_ix = make_word_to_ix(sents)\n",
    "    vectorized_sents = vectorize_sents(sents,word_to_ix)\n",
    "\n",
    "    vocab_size = len(word_to_ix)\n",
    "\n",
    "    return vectorized_sents, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21a9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
